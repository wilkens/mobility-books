{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6a072a3-f99c-4843-a454-81e2a7b33ee3",
   "metadata": {},
   "source": [
    "# Data prep and integration\n",
    "\n",
    "Load and integrate data and metadata for use in full analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85ce650d-289a-4c30-94fa-7aa2d138188f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports and setup\n",
    "from   ast import literal_eval\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from   scipy.stats import permutation_test\n",
    "import seaborn as sns\n",
    "from   sklearn.preprocessing import LabelBinarizer\n",
    "import string\n",
    "import warnings\n",
    "\n",
    "data_dir = os.path.join('..', 'data')\n",
    "derived_dir = os.path.join(data_dir, 'derived')\n",
    "metadata_dir = os.path.join(data_dir, 'metadata')\n",
    "\n",
    "# inputs\n",
    "conlit_file = 'CONLIT_CharData_AP_7.csv.gz'\n",
    "conlit_distance_file = 'CONLIT_CharData_distances_6.csv.gz'\n",
    "early_file_wi = 'EARLY_CharData_MW_2.csv.gz'\n",
    "early_file_ap = 'EARLY_CharData_02.csv.gz'\n",
    "early_file_full = None\n",
    "\n",
    "# outputs\n",
    "\n",
    "conlit_out_file = 'CONLIT_CharData_AP_MW_7.csv.gz'\n",
    "early_out_file =  'EARLY_CharData_AP_MW_7.csv.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678cc0e0-2b91-4fe4-bf47-adb882a9e7b1",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42fc8950-b13d-4693-85e3-7e839a440cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def string_to_list(x):\n",
    "    lst = literal_eval(x.replace(', nan', \"', ZZZZ'\").replace('[nan, ', \"'['\").replace(', nan]', \"']'\"))\n",
    "    return [i for i in lst if i != 'ZZZZ']\n",
    "\n",
    "def index_int_string(idx):\n",
    "    '''Make Chicago index labels consistent'''\n",
    "    try:\n",
    "        int(idx)\n",
    "        return(str(idx).rjust(8, '0'))\n",
    "    except ValueError:\n",
    "        return(idx)\n",
    "def source_mapper(label):\n",
    "    if label.startswith('eaf'):\n",
    "        return('eaf')\n",
    "    elif label.startswith('Wright'):\n",
    "        return('wright')\n",
    "    else:\n",
    "        return('chicago')\n",
    "\n",
    "# read CONLIT\n",
    "conlit = pd.read_csv(\n",
    "    os.path.join(derived_dir, conlit_file), \n",
    "    index_col='book_id',\n",
    "    converters={\n",
    "        'gpe_places': string_to_list,\n",
    "        'nongpe_places': string_to_list,\n",
    "        'all_places': string_to_list,\n",
    "        'gpe_sequences': string_to_list\n",
    "    },\n",
    ")\n",
    "conlit['source'] = 'conlit'\n",
    "conlit_distances = pd.read_csv(\n",
    "    os.path.join(derived_dir, conlit_distance_file), \n",
    "    index_col='book_id'\n",
    ")\n",
    "\n",
    "# read EARLY\n",
    "if early_file_wi:\n",
    "    early_wi = pd.read_csv(\n",
    "        os.path.join(derived_dir, early_file_wi), \n",
    "        index_col='book_id',\n",
    "        converters={\n",
    "            'gpe_places': string_to_list,\n",
    "            'nongpe_places': string_to_list,\n",
    "            'all_places': string_to_list,\n",
    "            'gpe_sequences': string_to_list\n",
    "        },\n",
    "    )\n",
    "    early_wi.index = early_wi.index.to_series().apply(index_int_string)\n",
    "    # set source corpus for EARLY data\n",
    "    early_wi['source'] = early_wi.index.to_series().apply(source_mapper)\n",
    "    early_wi = early_wi.loc[~early_wi.index.duplicated()]\n",
    "if early_file_ap:\n",
    "    early_ap = pd.read_csv(\n",
    "        os.path.join(derived_dir, early_file_ap), \n",
    "        index_col='book_id',\n",
    "        converters={\n",
    "            'gpe_places': string_to_list,\n",
    "            'nongpe_places': string_to_list,\n",
    "            'all_places': string_to_list,\n",
    "            'gpe_sequences': string_to_list\n",
    "        },\n",
    "    )\n",
    "    #early_ap.index = early.index.to_series().apply(index_int_string)\n",
    "    # set source corpus for EARLY data\n",
    "    #early['source'] = early.index.to_series().apply(source_mapper)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f5dabb-b671-4aca-a384-c2a3fdbc16e7",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d45135d2-6f81-49fd-94b9-a768f09622e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EAF and Wright\n",
    "eaf = pd.read_csv(\n",
    "    os.path.join(data_dir, 'metadata', 'eaf-wright-metadata.tsv'), \n",
    "    sep='\\t', \n",
    "    index_col='source_id'\n",
    ")\n",
    "eaf.index.rename('book_id', inplace=True)\n",
    "eaf.rename(columns={'gender':'author_gender'}, inplace=True)\n",
    "\n",
    "# Chicago\n",
    "chi = pd.read_csv(\n",
    "    os.path.join(metadata_dir, 'chicago-books.csv'),\n",
    "    index_col='BOOK_ID'\n",
    ")\n",
    "chi.index.rename('book_id', inplace=True)\n",
    "chi.index = chi.index.to_series().apply(index_int_string)\n",
    "chi.columns = [i.lower() for i in chi.columns]\n",
    "\n",
    "chi_auth = pd.read_csv(\n",
    "    os.path.join(metadata_dir, 'chicago-authors.csv'),\n",
    ")\n",
    "chi_auth.columns = [i.lower() for i in chi_auth.columns]\n",
    "\n",
    "chi_idx = chi.index\n",
    "chi = chi.merge(chi_auth[['auth_id', 'gender']], how='left', on='auth_id').set_index(chi_idx)\n",
    "chi.rename(columns={'gender':'author_gender', 'publ_date':'pub_date'}, inplace=True)\n",
    "chi['author'] = chi[['auth_last', 'auth_first']].agg(', '.join, axis=1)\n",
    "\n",
    "# CONLIT\n",
    "con = pd.read_csv(\n",
    "    os.path.join(metadata_dir, 'CONLIT_META.csv'),\n",
    "    index_col='ID'\n",
    ")\n",
    "con.index.rename('book_id', inplace=True)\n",
    "con.index = con.index.to_series().apply(lambda x: x[:-4]) #delete '.txt'\n",
    "# fix up indexing errors\n",
    "con.rename(\n",
    "    index={\n",
    "        '2009_LaFleur,Suzanne_Love,Aubrey_MGtxt':'2009_LaFleur,Suzanne_Love,Aubrey_M', \n",
    "        '2015_Jackson,AL_ComeToMeRecklessly_ROM.txt':'2015_Jackson,AL_ComeToMeRecklessly_ROM'\n",
    "    }, \\\n",
    "    inplace=True\n",
    ")\n",
    "con.columns = [i.lower() for i in con.columns]\n",
    "con.rename(columns={'pubdate':'pub_date', 'work_title':'title'}, inplace=True)\n",
    "con['author'] = con[['author_last', 'author_first']].fillna('').astype(str).agg(', '.join, axis=1)\n",
    "\n",
    "# integrate target columns\n",
    "cols = ['author', 'title', 'pub_date', 'author_gender']\n",
    "meta = pd.concat([eaf[cols], chi[cols], con[cols]], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fb193d-239a-41cd-8718-7457177b25dd",
   "metadata": {},
   "source": [
    "## Integrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3dbbf16-4735-414c-b2fc-089f2cfedc37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conlit = conlit.join(meta[['pub_date', 'author_gender']])\n",
    "early_wi = early_wi.join(meta[['pub_date', 'author_gender']])\n",
    "\n",
    "# set canonical values where needed\n",
    "early_wi['Category'] = 'FIC'\n",
    "early_wi.loc[(early_wi.source=='chicago') & (early_wi.pub_date<=1945), ['source']] = 'chicago_1'\n",
    "early_wi.loc[(early_wi.source=='chicago') & (early_wi.pub_date>1945), ['source']] = 'chicago_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d8ee8cb-2c60-494f-a026-fae88fe8520d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "early = early_ap.join(early_wi[['Start_Finish_Miles', 'Start_Finish_Z', 'Category', 'author_gender']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "939f8e3e-924d-4ae8-829b-af74fd15e27f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conlit = conlit.join(conlit_distances[['Start_Finish_Miles', 'Start_Finish_Z']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cab4962-d512-488b-b70a-e91782781fdc",
   "metadata": {},
   "source": [
    "## Dump integrated data to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3213ecca-a525-4760-a08e-fb2c61f7b3fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# just early metadata\n",
    "early_wi[['source']].join(meta).to_csv(os.path.join(metadata_dir, 'EARLY_META.tsv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1d78dbf-b756-4fa2-a062-bdb3a81013db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# full CONLIT and EARLY\n",
    "early.to_csv(\n",
    "    os.path.join(derived_dir, early_out_file)\n",
    ")\n",
    "conlit.to_csv(\n",
    "    os.path.join(derived_dir, conlit_out_file)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39deab15-5a8d-4cd1-a2e7-07b3121b5a28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
